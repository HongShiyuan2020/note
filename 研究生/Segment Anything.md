总结：
1. 本文参考NLP领域大语言基础模型的经验，旨在实现分割领域的基础模型。为此，本文围绕三个关键问题实现目的：要完成什么样的任务？设计什么样的模型？使用什么样的数据？本文期望达到NLP领域的zero-shot和few-shot性能的提出”在给出分割提示（关键点、框、文本等）后获取合理的分割遮罩“的任务，同时要满足抗歧义提示的能力（例如：给出一个关键点落在一个戴帽子的人的帽子上，给出的分割结果是帽子的遮罩还是人的遮罩）以及能满足实时交互的能力。![[Pasted image 20240809204856.png]]本文提出的模型由三部分组成：一个参数较重Image Encoder（将图片编码为图像嵌入表示）、多种提示编码器（把文本、关键点、框等等编码为相应编码）和一个轻量级的Mask Decoder（接受图像嵌入编码和提示编码生成对应遮罩）。需要注意的是，模型为了满足抗歧义性当给出一个提示时会输出多个预测的遮罩和对应置信度。为了满足实时性，Mask Decoder为轻量级网络。本文的任务需要大量分割数据，而现有的分割数据实验严重不足，因此，本文提出了SA-1B啊，包含11000000张图片和1.1B个分割遮罩。标注概述数据时，本文采取数据标注和模型训练相交互的模型，设计了一个Data Engine，首先使用现有数据集训练一个较弱的模型辅助人工标注得到一部分数据，数据量足够后，训练模型，循环往复，当需将足够大时，将模型Image Encoder 换成一个更大参数量的模型，使用现有数据训练，自动标注数据，人工标志遗漏的数据集，进一步扩大数据规模，训练模型。使得模型可以全自动标注。此外，SAM以文本提示得到遮罩的功能与我们的任务高度相关，他们的做法无需标注文本提示，借助CLIP将遮罩中的图片编码作Prompt Eocoder的输入，由于CLIP生成的图像编码和文本编码对齐，可以使用图像编码替换文本编码训练模型。