## 定义

图像分割是指将一幅图像划分成多个子区域或像素集合的过程，其中每个子区域或像素集合具有一定的统计特征或语义信息。图像分割有语义分割和实例分割的差别。

**语义分割**：不分离同一类的实例，我们只关心每个像素的类别，如果输入对象中有两个相同类别的对象，语义分割不将他们区分为单独的对象。
**实例分割**：是需要对对象个体进行区分的
## 传统算法

1. 基于阈值的分割算法：将图像中的像素按照其灰度值划分成若干个区域，通常采用单一阈值、多阈值和自适应阈值等方式进行分割。该算法简单易懂，适用于对比度较高的图像，但对于光照、噪声等因素的影响较大。
2. 基于边缘的分割算法：通过检测图像中的边缘或轮廓来进行分割，常用的算法包括Canny算法、Sobel算法等。该算法对于边缘比较明显的图像效果较好，但对于噪声和复杂背景的图像效果较差。
3. 基于区域的分割算法：将图像中的像素划分成若干个区域，并通过区域之间的相似性来进行分割。常用的算法包括K-means算法、分水岭算法等。该算法对于复杂背景和噪声比较多的图像效果较好，但对于分割结果的评估和优化比较困难。
4. 基于能量的分割算法：通过定义能量函数来进行图像分割，常用的算法包括GrabCut算法、GraphCut算法等。该算法对于图像的分割效果较好，但计算复杂度较高，需要较长的运行时间。
## 深度学习算法

语义分割任务最初流行的深度学习方法是图像块分类（patch classification），即利用像素周围的图像块对每一个像素进行独立的分类。使用图像块分类的主要原因是分类网络中包含**全连接层**（fully connected layer），它需要固定尺寸的图像。

2014 年，加州大学伯克利分校的 Long等人提出全卷积网络（FCN），这使得卷积神经网络无需全连接层即可进行密集的像素预测。使用这种方法可生成任意大小的图像分割图，且该方法比图像块分类法要高效许多。之后，语义分割领域几乎所有先进方法都采用了类似结构。

使用卷积神经网络进行语义分割存在的另一个大问题是**池化层**。池化层虽然扩大了感受野、聚合语境，但因此造成了位置信息的丢失。但是，语义分割要求类别图完全贴合，因此需要保留位置信息。

有两种不同结构来解决该问题。
- 第一个是**编码器解码器结构**。编码器逐渐减少池化层的空间维度，解码器逐步修复物体的细节和空间维度。编码器和解码器之间通常存在快捷连接，因此能帮助解码器更好地修复目标的细节。U-Net是这种方法中最常用的结构。
- 第二种方法使用**空洞/扩张卷积（dilated/atrous convolutions）结构**，来去除池化层。

针对语义分割任务构建神经网络架构的最简单的方法是简单地堆叠多个卷积层（使用same填充以维持维度）并输出最终的分割图。这种结构通过特征映射的连续变换，直接去学习从输入图像到其对应分割的映射，**缺点是在整个网络中保持全分辨率的计算成本非常高。**
![[Pasted image 20240611084747.png]]
图像分割领域现在较为流行的是**编码器解码器结构**，其中我们对输入的空间分辨率进行下采样，生成分辨率较低的特征映射，它能高效地进行分类，而后使用上采样将特征还原为全分辨率分割图。
### 上采样与下采样
![[Pasted image 20240611084218.png]]
某些大小的滤波器会在输出特征映射中产生重叠（例如，具有步幅 ![公式](https://www.zhihu.com/equation?tex=2) 的 ![公式](https://www.zhihu.com/equation?tex=3%20%5Ctimes%203) 滤波器 - 如下面的示例所示），如果只是简单将重叠值加起来，往往会在输出中产生棋盘格子状的伪影（artifact）。
![[Pasted image 20240611084652.png]]

### 主流分割模型
#### FCN全卷积网络
![[Pasted image 20240611085132.png]]
全卷积网络FCN在会议CVPR 2015的论文 [Fully Convolutional Networks for Semantic Segmentation](https://arxiv.org/pdf/1411.4038) 中提出。它将CNN分类网络（AlexNet, VGG 和 GoogLeNet）修改为全卷积网络，通过对分割任务进行微调，将它们学习的表征转移到网络中。然后，定义了一种新的架构，它将深的、粗糙的网络层的语义信息和浅的、精细的网络层的表层信息结合起来，来生成精确和详细的分割。全卷积网络在 PASCAL VOC（2012年的数据，相对之前的方法提升了 $20\%$，达到 $62.2\%$ 的平均IoU），NYUDv2 和 SIFT Flow 上实现了最优的分割结果，对于一个典型的图像，推断只需要 $\frac{1}{3}$秒的时间。

**关键特点**：
- FCN的特征由编码器中的不同阶段合并而成的，它们在**语义信息的粗糙程度**上有所不同。
- 低分辨率语义特征图的上采样使用**经双线性插值滤波器初始化的「反卷积」操作完成**。
- 从 VGG16、Alexnet 等分类器网络进行知识迁移来实现语义细分。

在传统的分类 CNNs 中，**池化操作用来增加视野，同时减少特征图的分辨率**。对分类任务来说非常有效，分类模型关注图像总体类别，而对其空间位置并不关心。所以才会有频繁的卷积层之后接池化层的结构，保证能提取更多抽象、突出类的特征。另一方面，**池化和带步长的卷积对语义分割是不利的**，这些操作会带来空间信息的丢失。不同的语义分割模型在**解码器**中使用了不同机制，但目的都在于恢复在**编码器**中降低分辨率时丢失的信息。

#### SegNet
![[Pasted image 20240611091138.png]]
SegNet在2015的论文 [SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation](https://arxiv.org/pdf/1505.07293) 中提出。

SegNet 的新颖之处在于解码器对其较低分辨率的输入特征图进行上采样的方式。**解码器使用了在相应编码器的最大池化步骤中计算的池化索引来执行非线性上采样**。这种方法消除了学习上采样的需要。经上采样后的特征图是稀疏的，因此随后使用可训练的卷积核进行卷积操作，生成密集的特征图。

**关键特点**：
- SegNet 在解码器中使用「**反池化**」对特征图进行上采样，并在分割中保持高频细节的完整性。
- 编码器舍弃掉了全连接层（和 FCN 一样进行卷积），因此是拥有较少参数的轻量级网络。

![[Pasted image 20240611091700.png]]
如上图所示，**编码器中的每一个最大池化层的索引都被存储起来，用于之后在解码器中使用那些存储的索引来对相应的特征图进行反池化操作**。虽然这有助于保持高频信息的完整性，但当对低分辨率的特征图进行反池化时，它也会忽略邻近的信息。

#### U-Net
![[Pasted image 20240611091941.png]]
U-Net在2015的论文 [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/pdf/1505.04597) 中提出。

U-Net 架构包括一个「捕获上下文信息的收缩路径」和一个「支持精确本地化的对称扩展路径」。这样一个网络可以使用非常少的图像进行端到端的训练，它在ISBI神经元结构分割挑战赛中取得了比之前方法都更好的结果。

**关键特点**：
- U-Net 简单地将**编码器**的特征图拼接至每个阶段**解码器**的上采样特征图，从而形成一个U形结构。该网络非常类似于 **Ladder Network** 类型的架构。
- 通过跳跃 `拼接` 连接的架构，在每个阶段都允许解码器学习在编码器池化中丢失的相关特征。
- 上采样采用转置卷积。

U-Net 在 EM 数据集上取得了最优异的结果，该数据集只有30个密集标注的医学图像和其他医学图像数据集，U-Net 后来扩展到3D版的 **3D-U-Net**。虽然 U-Net 最初的发表在于其在生物医学领域的分割、网络的实用性以及从非常少的数据中学习的能力，但现在已经成功应用其他几个领域，例如 **卫星图像分割**等。

#### DeepLab V1
DeepLab V1在论文 [Semantic Image Segmentation with deep convolutional nets and fully connected CRFs](https://arxiv.org/pdf/1412.7062) 中提出。

DeepLab V1结合 DCNN 和概率图模型来解决语义分割问题。DCNN 最后一层的响应不足以精确定位目标边界，这是 DCNN 的不变性导致的。DeepLab V1的解决方法是：在最后一层网络后结合全连接条件随机场。DeepLab V1在 PASCAL VOC 2012 上达到了 71.6% 的 mIoU。

**关键特点**：
- 提出 **空洞卷积（atrous convolution）（又称扩张卷积（dilated convolution））** 。
- 在最后两个最大池化操作中不降低特征图的分辨率，并在倒数第二个最大池化之后的卷积中使用空洞卷积。
- 使用 **CRF（条件随机场）[^CRF]** 作为后处理，恢复边界细节，达到准确定位效果。
- 附加输入图像和前四个最大池化层的每个输出到一个两层卷积，然后拼接到主网络的最后一层，达到 **多尺度预测** 效果。

#### DeepLab V2
![[Pasted image 20240611095514.png]]
DeepLab V2 在2017的论文 [DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs](https://arxiv.org/pdf/1606.00915) 中提出。

DeepLab V2 提出了一种空洞空间金字塔池化（ASPP）的多尺度鲁棒分割方法。
ASPP 使用多个采样率的过滤器和有效的视野探测传入的卷积特征层，从而在多个尺度上捕获目标和图像上下文。再结合 DCNNs 方法和概率图形模型，改进了目标边界的定位。DCNNs 中常用的最大池化和下采样的组合实现了不变性，但对定位精度有一定的影响。DeepLab V2通过将 DCNN 最后一层的响应与一个全连接条件随机场(CRF)相结合来克服这个问题。DeepLab V2 在 PASCAL VOC 2012 上得到了 $79.7\%$ 的 mIoU。DeepLab V2的主干网络是ResNet，整体网络如下图所示，核心的一些结构包括 空洞卷积组建的ASPP模块、空洞空间金字塔池化。
#### DeepLab V3
![[Pasted image 20240611100810.png]]
DeepLab V3在论文 [Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/pdf/1706.05587) 中提出。

DeepLab V3 依旧使用了ResNet 作为主干网络，也依旧应用空洞卷积结构。为了解决多尺度目标的分割问题，DeepLab V3 串行/并行设计了能够捕捉多尺度上下文的模块，模块中采用不同的空洞率。此外，DeepLab V3 增强了先前提出的空洞空间金字塔池化模块，增加了图像级特征来编码全局上下文，使得模块可以在多尺度下探测卷积特征。DeepLab V3 模型在没有 CRF 作为后处理的情况下显著提升了性能。

#### Mask R-CNN
![[Pasted image 20240611101200.png]]
Mask R-CNN以Faster R-CNN 为基础，在现有的边界框识别分支基础上添加一个并行的预测目标掩码的分支。Mask R-CNN很容易训练，仅仅在 Faster R-CNN 上增加了一点小开销，运行速度为 5fps。此外，Mask R-CNN很容易泛化至其他任务，例如，可以使用相同的框架进行姿态估计。Mask R-CNN在 COCO 所有的挑战赛中都获得了最优结果，包括实例分割，边界框目标检测，和人关键点检测。在没有使用任何技巧的情况下，Mask R-CNN 在每项任务上都优于所有现有的单模型网络，包括 COCO 2016 挑战赛的获胜者。

在Faster R-CNN 上添加辅助分支以执行语义分割
- 对每个实例进行的 **RoIPool** 操作已经被修改为 **RoIAlign** ，它避免了特征提取的空间量化，因为在最高分辨率中保持空间特征不变对于语义分割很重要。
- Mask R-CNN 与 **Feature Pyramid Networks**（类似于PSPNet，它对特征使用了金字塔池化）相结合，在 **MS COCO** 数据集上取得了最优结果。
#### PSPNet
![[Pasted image 20240611101855.png]]
PSPNet利用基于不同区域的上下文信息集合，通过我们的金字塔池化模块，使用提出的金字塔场景解析网络（PSPNet）来发挥全局上下文信息的能力。全局先验表征在场景解析任务中产生了良好的质量结果，而 PSPNet 为像素级的预测提供了一个更好的框架，该方法在不同的数据集上达到了最优性能。它首次在2016 ImageNet 场景解析挑战赛，PASCAL VOC 2012 基准和 Cityscapes 基准中出现。
#### RefineNet
![[Pasted image 20240611102417.png]]
RefineNet是一个通用的多路径优化网络，它明确利用了整个下采样过程中可用的所有信息，使用远程残差连接实现高分辨率的预测。通过这种方式，可以使用早期卷积中的细粒度特征来直接细化捕捉高级语义特征的更深的网络层。RefineNet 的各个组件使用遵循恒等映射思想的残差连接，这允许网络进行有效的端到端训练。

**关键特点**：
- 使用**多分辨率**作为输入，将提取的特征融合在一起，并将其传递到下一个阶段。
- 引入**链式残差池化**，可以从一个大的图像区域获取背景信息。它通过多窗口尺寸有效地池化特性，利用残差连接和学习权重方式融合这些特征。
- 所有的特征融合都是使用`sum`（ResNet 方式）来进行端到端训练。
- 使用普通 ResNet 的残差层，**没有计算成本高的空洞卷积**
## 语义分割任务评估
对于语义分割任务，我们会通过 **mIoU（mean Intersection-Over-Union） 和 mAcc（mean Accuracy）** 指标来进行效果评估。
分割网络的评价指标：mIoU
- mloU：分割每一类别的交并比（IOU）
![[Pasted image 20240611083341.png]]
分割网络的评价指标：mAcc
- mAcc：Pred和GT对应位置的分类准确率
![[Pasted image 20240611083434.png]]

[^CRF]: 